{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n",
      "Num GPUs Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n",
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import path\n",
    "import sys\n",
    "import math\n",
    "import cv2 # Read raw image\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import ndimage # For rotation task or\n",
    "import imutils\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray\n",
    "from skimage.io import imsave\n",
    "from skimage.transform import resize\n",
    "from pprint import pprint\n",
    "# from numpy.linalg import norm\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.utils import data_utils\n",
    "from tensorflow.keras.preprocessing.image import Iterator\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, AveragePooling2D, MaxPooling2D, Reshape, Conv2DTranspose, ZeroPadding2D, Add\n",
    "from tensorflow.keras.layers import Activation, InputLayer, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.layers import PReLU\n",
    "\n",
    "\n",
    "# Check to see if GPU is being used\n",
    "print(tensorflow.test.gpu_device_name())\n",
    "print(\"Num GPUs Available: \", tf.config.experimental.list_physical_devices('GPU'))\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PATH = \"/home/satyarth934/data/modis_data_products/*/array_3bands_normalized/448/*\"\n",
    "# DATA_PATH = \"/home/satyarth934/data/modis_data_products/terra/array_3bands_adapted/448/mean_stdev_removed/*\" # <- needs to be normalized\n",
    "DATA_PATH = \"/home/satyarth934/data/modis_data_products/terra/array_3bands_adapted/448/median_removed/*\" # <- needs to be normalized\n",
    "NORMALIZE = True\n",
    "\n",
    "MODEL_NAME = \"baseAE_median\"\n",
    "BASE_DIR = \"/home/satyarth934/code/FDL_2020/\"\n",
    "\n",
    "OUTPUT_MODEL_PATH = BASE_DIR + \"Models/\" + MODEL_NAME\n",
    "TENSORBOARD_LOG_DIR = BASE_DIR + \"tb_logs/\" + MODEL_NAME\n",
    "ACTIVATION_IMG_PATH = BASE_DIR + \"activation_viz/\" + MODEL_NAME\n",
    "PATH_LIST = BASE_DIR + \"Features/\" + MODEL_NAME + \"_filenames.pkl\"\n",
    "FEATURES_OUTPUT = BASE_DIR + \"Features/\" + MODEL_NAME + \"_features.pkl\"\n",
    "\n",
    "NUM_EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(img_paths): 365\n",
      "X_test: (73, 448, 448, 3)\n",
      "0.10003613763570497\n",
      "Before normalization\n",
      "-0.3387008713849291 0.9136310171941195\n",
      "After normalization\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# NEW MODIS DATASET\n",
    "\n",
    "img_paths = glob.glob(DATA_PATH)\n",
    "print(\"len(img_paths):\", len(img_paths))\n",
    "random.seed(a=13521)\n",
    "random.shuffle(img_paths)\n",
    "\n",
    "train_test_split = 0.8\n",
    "X_test_paths = img_paths[int(train_test_split*len(img_paths)):]\n",
    "\n",
    "dims=(448,448,3)\n",
    "\n",
    "# Loading Testing Data\n",
    "X_test = np.empty((len(X_test_paths),*dims))\n",
    "for i, p in enumerate(X_test_paths):\n",
    "    X_test[i,:,:,:] = np.load(p)\n",
    "\n",
    "print(\"X_test:\", X_test.shape)\n",
    "\n",
    "# To check what percentage of pixels are 'nan'\n",
    "print(np.sum(np.isnan(X_test)) / np.prod(X_test.shape))\n",
    "\n",
    "# Checking min max to see if normalization is needed or not\n",
    "print(\"Before normalization\")\n",
    "print(np.nanmin(X_test), np.nanmax(X_test))\n",
    "\n",
    "# Normalize Inputs\n",
    "def normalize(mat):\n",
    "    valid_cells = np.invert(np.isnan(mat))\n",
    "    normalized = np.subtract(mat, np.nanmin(mat), where=valid_cells) / (np.nanmax(mat) - np.nanmin(mat))\n",
    "    return normalized\n",
    "\n",
    "X_test = normalize(X_test)\n",
    "\n",
    "# Checking min max after normalization \n",
    "print(\"After normalization\")\n",
    "print(np.nanmin(X_test), np.nanmax(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = load_model(\"../Models/\" + MODEL_NAME)\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af372401ffe3477abdd36ea6f1c8f357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=73.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to featurize the input\n",
    "def extract_features(img_array, model):\n",
    "#     img_array = image.img_to_array(img)\n",
    "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "#     preprocessed_img = preprocess_input(expanded_img_array)\n",
    "    features = model.predict(expanded_img_array)\n",
    "    flattened_features = features.flatten()\n",
    "    normalized_features = flattened_features / np.linalg.norm(flattened_features)\n",
    "    return normalized_features\n",
    "\n",
    "# Dataset location\n",
    "\n",
    "# Featurize all input images\n",
    "feature_list = []\n",
    "for i in tqdm_notebook(range(len(X_test))):\n",
    "    feature_list.append(extract_features(X_test[i,:,:,:], model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(602112,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the features and the filelist order for later use.\n",
    "pickle.dump(feature_list, file=open((FEATURES_OUTPUT), mode = 'wb'))\n",
    "pickle.dump(X_test_paths, file = open((PATH_LIST), mode = 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
