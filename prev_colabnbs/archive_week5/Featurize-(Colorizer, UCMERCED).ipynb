{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Featurize-(Colorizer, UCMERCED).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sV8t5w20uMRU","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"561rrpfX_VaY","colab_type":"text"},"source":["**Featurize Data**\n","\n","*Summary of this notebook:*  \n","Obtain a low-dimensional feature vector for each image in an input dataset using a ImageNet based pretrained model (MobileNet, here). Load the dataset in a generator object, preprocess based on the model, run predict on every image to obtain a feature vector. Save the feature vector and the filenames in a separate pickle file.\n","\n","*Definition of Done:*"]},{"cell_type":"code","metadata":{"id":"PeVQm4uxJH9U","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594743146051,"user_tz":420,"elapsed":346,"user":{"displayName":"Nishan Srishankar","photoUrl":"","userId":"11074479106454986489"}},"outputId":"d22d6e75-95b8-4fa3-ea41-2978c80c598d"},"source":["from google.colab import drive\n","import os\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kWxOCMn_JRi7","colab_type":"code","colab":{}},"source":["os.chdir(\"/content/gdrive/Shared drives/2020_FDLUSA_Earth Science_Knowledge Discovery Framework/Code\")\n","# !ls -lht"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m5jn6I3fH4DW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594743156117,"user_tz":420,"elapsed":7348,"user":{"displayName":"Nishan Srishankar","photoUrl":"","userId":"11074479106454986489"}},"outputId":"6ba77c3d-dc0f-4666-ac82-57cfc6691cfb"},"source":["# Imports from Colab 2\n","import math\n","import numpy as np\n","import pickle\n","import keras\n","import tensorflow\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Import pretrained model\n","# from tensorflow.keras.applications import MobileNet, ResNet50\n","# from tensorflow.keras.applications.resnet50 import preprocess_input"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Zxxy4JPUZ0TX","colab_type":"code","colab":{}},"source":["# Imports for Colab 6\n","import cv2 # Read raw image\n","import glob\n","from google.colab.patches import cv2_imshow\n","from matplotlib import pyplot as plt\n","from scipy import ndimage # For rotation task or\n","import imutils\n","from tensorflow.keras import Model\n","from tensorflow.keras.layers import Dense, Flatten, Dropout\n","from tensorflow.keras.optimizers import Adam\n","\n","from tensorflow.python.keras.utils import data_utils\n","from tensorflow.keras.preprocessing.image import Iterator\n","\n","# Imports for Colorizer\n","from os import path\n","from tensorflow.keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n","from tensorflow.keras.layers import Activation, InputLayer, BatchNormalization\n","from tensorflow.keras.callbacks import TensorBoard\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","from skimage.color import rgb2lab, lab2rgb, rgb2gray\n","from skimage.io import imsave\n","import random\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"blkgw5s-apyH","colab_type":"code","colab":{}},"source":["# For loading pretrained models\n","from tensorflow.keras.models import load_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qjke8eMWh1Dt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594743165761,"user_tz":420,"elapsed":8446,"user":{"displayName":"Nishan Srishankar","photoUrl":"","userId":"11074479106454986489"}},"outputId":"5ad9bc56-ae7a-4834-91c3-bb2e0e4799d9"},"source":["tensorflow.test.gpu_device_name()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"xsFRSgptJ5jH","colab_type":"code","colab":{}},"source":["## FOR UC-MERCED\n","# dataset = \"MODIS_MCD43A4\"\n","# dataPath = (\"Datasets/\"+ dataset+ \"/Globe/Test/test_set/\")\n","\n","## FOR CLOUDSTREET-SMALLER\n","# dataset=\"nasa_impact/cloudstreet_smaller\"\n","# dataPath = (\"Datasets/\"+ dataset+ \"/\")\n","\n","\n","# Colorizer needs array setup as well unfortunately\n","# dims=(256,256,3)\n","# image_globs=glob.glob(dataPath+'/*/np_arrays/*.npy')\n","# print(len(image_globs))\n","# X=np.empty((0,*dims))\n","\n","# for f in image_globs:\n","#   image=np.expand_dims(img_to_array(load_img(f,target_size=dims))/255.,0)\n","#   X=np.vstack((X,image))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hm4rPIrI2IAo","colab_type":"code","colab":{}},"source":["# name='merced_x.npy'\n","# # with open(name, 'wb') as f:\n","# #   np.save(f,X,allow_pickle=True)\n","# X=np.load(name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0W7RiXQmNinE","colab_type":"text"},"source":["Import Model\n","\n"]},{"cell_type":"code","metadata":{"id":"Pops6IGUaXqC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":910},"executionInfo":{"status":"ok","timestamp":1594743177781,"user_tz":420,"elapsed":2911,"user":{"displayName":"Nishan Srishankar","photoUrl":"","userId":"11074479106454986489"}},"outputId":"efe867bb-a71b-421a-c9ee-731655a5c13d"},"source":["##  Basic convolution LAB colorization semi-supervised\n","modelPath='Models/Colorization_CustomCNN_epoch30_ucmerced'\n","\n","model=load_model(modelPath)\n","\n","model.summary()\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 256, 256, 32)      896       \n","_________________________________________________________________\n","average_pooling2d (AveragePo (None, 85, 85, 32)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 43, 43, 32)        9248      \n","_________________________________________________________________\n","average_pooling2d_1 (Average (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 7, 7, 64)          36928     \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 7, 7, 128)         73856     \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 4, 4, 128)         147584    \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 4, 4, 256)         295168    \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 4, 4, 256)         590080    \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 4, 4, 128)         295040    \n","_________________________________________________________________\n","up_sampling2d (UpSampling2D) (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 8, 8, 128)         147584    \n","_________________________________________________________________\n","up_sampling2d_1 (UpSampling2 (None, 16, 16, 128)       0         \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 16, 16, 64)        73792     \n","_________________________________________________________________\n","up_sampling2d_2 (UpSampling2 (None, 32, 32, 64)        0         \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 32, 32, 64)        36928     \n","_________________________________________________________________\n","up_sampling2d_3 (UpSampling2 (None, 64, 64, 64)        0         \n","_________________________________________________________________\n","up_sampling2d_4 (UpSampling2 (None, 128, 128, 64)      0         \n","_________________________________________________________________\n","conv2d_12 (Conv2D)           (None, 128, 128, 3)       1731      \n","_________________________________________________________________\n","up_sampling2d_5 (UpSampling2 (None, 256, 256, 3)       0         \n","=================================================================\n","Total params: 1,727,331\n","Trainable params: 1,727,331\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N5BNIPAtdloM","colab_type":"code","colab":{}},"source":["final_desired_layer=-11"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w3muMk62bwuB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"status":"ok","timestamp":1594743179809,"user_tz":420,"elapsed":281,"user":{"displayName":"Nishan Srishankar","photoUrl":"","userId":"11074479106454986489"}},"outputId":"f9294a1a-0215-462d-a437-28ba24a2522b"},"source":["submodel=Model(model.inputs, (model.layers[final_desired_layer].output))\n","# submodel=\n","submodel_pipeline=Sequential()\n","submodel_pipeline.add(submodel)\n","\n","# submodel_pipeline.add(Conv2D(20,(1, 1),activation=None, padding='same',use_bias=False,kernel_initializer='ones'))\n","\n","submodel_pipeline.add(Flatten())\n","## Stack 1x1 conv\n","submodel_pipeline.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","model (Model)                (None, 4, 4, 128)         1467296   \n","_________________________________________________________________\n","flatten (Flatten)            (None, 2048)              0         \n","=================================================================\n","Total params: 1,467,296\n","Trainable params: 1,467,296\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UwuJB526Ykip","colab_type":"text"},"source":["Get Data & Preprocess"]},{"cell_type":"code","metadata":{"id":"vDJ4NOnPj8ZJ","colab_type":"code","colab":{}},"source":["class CustomDataGenerator(data_utils.Sequence):\n","    'Generates data for Keras'\n","    def __init__(self, list_IDs, batch_size=16, dim=(400,400,3), shuffle=True):\n","        'Initialization'\n","        self.dim = dim\n","        self.batch_size = batch_size\n","        self.list_IDs = list_IDs\n","        self.shuffle = shuffle\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        return int(np.floor(len(self.list_IDs) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","\n","        # Find list of IDs\n","        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n","\n","        # Generate data\n","        X = self.__data_generation(list_IDs_temp)\n","        print(X.shape)\n","        return X\n","\n","    def on_epoch_end(self):\n","        'Updates indexes after each epoch'\n","        self.indexes = np.arange(len(self.list_IDs))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generation(self, list_IDs_temp):\n","        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n","        # Initialization\n","        X = np.empty((self.batch_size, *self.dim))\n","        for i,f in enumerate(list_IDs_temp):\n","            x_temp = np.load(f)\n","            if np.sum(x_temp.shape) < np.sum((400,400,3)):\n","              continue\n","            X[i,] = x_temp\n","\n","        gray_batch=rgb2gray(X)\n","\n","        X_batch=gray_batch[:,:,:]/255.\n","        # Y_batch=X[:,:,:,:]/255.\n","        X_batch=np.expand_dims(X_batch,3)\n","        # return X_batch,Y_batch\n","        return X_batch\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TSv2aeTDmvxO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":343},"executionInfo":{"status":"ok","timestamp":1594317708945,"user_tz":240,"elapsed":52939,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}},"outputId":"9a0ba948-1d1f-4dd0-8b21-70f873de27b3"},"source":["# inference = submodel_pipeline.predict(x=dataGenerator, batch_size=batch_size, use_multiprocessing=True, workers=2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(256, 400, 400, 1)\n","WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","(256, 400, 400, 1)\n","(256, 400, 400, 1)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/skimage/color/colorconv.py:794: RuntimeWarning: invalid value encountered in matmul\n","  return rgb @ coeffs\n"],"name":"stderr"},{"output_type":"stream","text":["(256, 400, 400, 1)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/skimage/color/colorconv.py:794: RuntimeWarning: invalid value encountered in matmul\n","  return rgb @ coeffs\n"],"name":"stderr"},{"output_type":"stream","text":["(256, 400, 400, 1)\n","(256, 400, 400, 1)\n","(256, 400, 400, 1)\n","(256, 400, 400, 1)\n","(256, 400, 400, 1)\n","(256, 400, 400, 1)\n","(256, 400, 400, 1)\n","(256, 400, 400, 1)\n","WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nyUVEAQFteBL","colab_type":"code","colab":{}},"source":["# Writing the features to the drive\n","pickle.dump(inference, file=open((\"Features/\" + modelName + \"_\" + dataset + \"_features.pkl\"), mode = 'wb'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1mz-CjcN5BEV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"status":"ok","timestamp":1594743552300,"user_tz":420,"elapsed":358444,"user":{"displayName":"Nishan Srishankar","photoUrl":"","userId":"11074479106454986489"}},"outputId":"aec699cb-9370-4b01-fd39-12dac7513e88"},"source":["train_path='Datasets/UCMerced_LandUse/Splits_2/train/'\n","test_path='Datasets/UCMerced_LandUse/Splits_2/val/'\n","combined_path='Datasets/UCMerced_LandUse/Images/'\n","\n","dataGenerator = ImageDataGenerator(rotation_range=20,\n","                                   width_shift_range=0.1,\n","                                   height_shift_range=0.1,\n","                                   zoom_range=0.1,\n","                                   horizontal_flip=True)\n","\n","def batch_grayrgb(batch_size):\n","  for batch in dataGenerator.flow_from_directory(combined_path,batch_size=batch_size):\n","    # print(len(batch),batch[0].shape)\n","    gray_batch=rgb2gray(batch[0]) #batch_size,h,w\n","    # print(gray_batch.shape)\n","    gray_batch=np.expand_dims(gray_batch,3)\n","    # print(gray_batch)\n","    gray_batch=np.repeat(gray_batch,3,axis=3) #batch_size,h,w,3\n","    # print(gray_batch.shape)\n","    X_batch=gray_batch\n","    Y_batch=batch[0]\n","    # print(np.min(X_batch),np.max(X_batch),np.min(Y_batch),np.max(Y_batch))\n","    yield X_batch,Y_batch\n","\n","\n","batch_size = 105\n","\n","\n","inference=submodel_pipeline.predict_generator(batch_grayrgb(batch_size),max_queue_size=3,verbose=1,workers=3,use_multiprocessing=True,steps=2100/batch_size)\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-10-1d6fc58c3b7c>:29: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use Model.predict, which supports generators.\n","Found 2100 images belonging to 21 classes.\n","WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n","WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","20/20 [==============================] - 313s 16s/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nYCzh17BBtkO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594743553245,"user_tz":420,"elapsed":925,"user":{"displayName":"Nishan Srishankar","photoUrl":"","userId":"11074479106454986489"}},"outputId":"055eee32-3d48-4f29-cbfd-407af3fcec56"},"source":["print(inference.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(2100, 2048)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ao_jglsh_p-4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594743603388,"user_tz":420,"elapsed":623,"user":{"displayName":"Nishan Srishankar","photoUrl":"","userId":"11074479106454986489"}},"outputId":"aaea9dab-5145-442f-ae1a-d585b77991dc"},"source":["fnames=dataGenerator.flow_from_directory(combined_path).filenames\n","pickle.dump(inference, file=open((\"Features/\" + 'customcolorizer' + \"_\" + 'merced_combined' + \"_features.pkl\"), mode = 'wb'))\n","pickle.dump(fnames, file = open((\"Features/\" + 'customcolorizer' + \"_\" + 'merced_combined' + \"_filenames.pkl\"), mode = 'wb'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 2100 images belonging to 21 classes.\n"],"name":"stdout"}]}]}