{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pt4_train.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPLuIKoPGBNca8kBQ1V1XK3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"eM9znyqrHl63","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1595465394553,"user_tz":240,"elapsed":1206,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}},"outputId":"d07c453f-84fa-44a5-8356-42a57937b1d9"},"source":["# Mount Google drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0YNe9PEOHqQS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595465394553,"user_tz":240,"elapsed":991,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}}},"source":["# Change to current dataset\n","import os\n","os.chdir(\"/content/gdrive/Shared drives/2020_FDLUSA_Earth Science_Knowledge Discovery Framework/Code/Cleaned_Code\")"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"w_b79UvKHxVs","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595465937982,"user_tz":240,"elapsed":1275,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}}},"source":["# Module Imports\n","import cv2\n","import glob\n","import math\n","import keras\n","import pickle\n","import random\n","import imutils\n","import numpy as np\n","import tensorflow as tf\n","from datetime import datetime\n","from matplotlib import pyplot as plt\n","\n","from os import path\n","from skimage.io import imsave\n","from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n","from scipy import ndimage # For rotation task or\n","from google.colab.patches import cv2_imshow\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import MobileNet, ResNet50\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","from tensorflow.keras import Model\n","from tensorflow.keras.layers import Dense, Flatten, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.python.keras.utils import data_utils\n","from tensorflow.keras.preprocessing.image import Iterator\n","from tensorflow.keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, AveragePooling2D, Reshape, Conv2DTranspose, ZeroPadding2D\n","from tensorflow.keras.layers import Activation, Input, InputLayer, BatchNormalization\n","from tensorflow.keras.callbacks import TensorBoard\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"7OMsVqo0IcLH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595465397904,"user_tz":240,"elapsed":2606,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}},"outputId":"0bc026da-a4af-4b0d-9e8a-374cdde4e15c"},"source":["# Check to see if GPU is being used\n","tf.test.gpu_device_name()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"IceYmB3XIeKF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595465398510,"user_tz":240,"elapsed":2188,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}}},"source":["# Dataset locations - TO BE MODIFIED FOR NEW DATASET\n","extensions = ['.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG', '.tif']\n","def get_file_list(root_dir):\n","    file_list = []\n","    for root, directories, filenames in os.walk(root_dir):\n","        for filename in filenames:\n","            # print(\"filename:\", filename)\n","            if any(ext in filename for ext in extensions):\n","                file_list.append(os.path.join(root, filename))\n","    return file_list\n","\n","# Dataset location\n","root_dir = '/content/gdrive/Shared drives/2020_FDLUSA_Earth Science_Knowledge Discovery Framework/Code/Datasets/UCMerced_LandUse/Images/Splits_3/'\n","train_filenames = sorted(get_file_list(root_dir + \"train\"))\n","val_filenames = sorted(get_file_list(root_dir + \"val\"))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"cNPAMwE2IrZg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595465989563,"user_tz":240,"elapsed":1227,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}}},"source":["dims = (448, 448, 3)\n","bool_generate=False\n","batch_size = 32\n","\n","# Network Architecture - TO BE MODIFIED FOR NEW MODELS\n","def createModel():\n","    model = Sequential(name=\"encoder\")\n","    model.add(Input(shape=dims))\n","    \n","    # Encoder\n","    model.add(Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", strides=2))\n","    model.add(Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"))\n","    model.add(Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\", strides=2))\n","    model.add(Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"))\n","    model.add(Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\", strides=2))\n","    model.add(Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\"))\n","    model.add(Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\",strides=3))\n","    model.add(Conv2D(15, (3, 3), activation=\"relu\", padding=\"same\"))\n","    model.add(Conv2D(5,  (3, 3), activation=\"relu\", padding=\"same\"))\n","    \n","    # Decoder\n","    model.add(Conv2DTranspose(128, (3, 3), activation=\"relu\", padding=\"same\"))\n","    model.add(UpSampling2D((2, 2)))\n","    model.add(Conv2DTranspose(64, (3, 3), activation=\"relu\", padding=\"same\"))\n","    model.add(Conv2DTranspose(64, (3, 3), activation=\"relu\", padding=\"same\"))\n","    model.add(UpSampling2D((2, 2)))\n","    model.add(Conv2DTranspose(32, (3, 3), activation=\"relu\", padding=\"same\"))\n","    model.add(Conv2D(3, (3, 3), activation=\"tanh\", padding=\"same\"))\n","    model.add(UpSampling2D((2, 2)))\n","\n","    return model"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"FSWod54cLDHk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":768},"executionInfo":{"status":"ok","timestamp":1595465989867,"user_tz":240,"elapsed":1180,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}},"outputId":"07e7d9b7-5482-4d26-8c0d-a25a981376ac"},"source":["from keras import backend as K\n","def f1(y_true, y_pred):\n","    y_pred = K.round(y_pred)\n","    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n","    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n","    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n","    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n","\n","    p = tp / (tp + fp + K.epsilon())\n","    r = tp / (tp + fn + K.epsilon())\n","\n","    f1 = 2*p*r / (p+r+K.epsilon())\n","    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n","    return K.mean(f1)\n","\n","def f1_loss(y_true, y_pred):\n","    \n","    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n","    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n","    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n","    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n","\n","    p = tp / (tp + fp + K.epsilon())\n","    r = tp / (tp + fn + K.epsilon())\n","\n","    f1 = 2*p*r / (p+r+K.epsilon())\n","    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n","    return 1 - K.mean(f1)\n","\n","\n","model = createModel()\n","model.compile(optimizer='adam',loss=[tf.keras.losses.BinaryCrossentropy(),f1_loss],loss_weights=[0.5, 0.5],metrics=['accuracy',f1,tf.keras.metrics.BinaryCrossentropy()])\n","callback_earlystop=EarlyStopping(monitor='loss',patience=5)\n","\n","checkpoint_filepath = 'Models/checkpoint/model2_{epoch:04d}.h5'\n","callback_checkpoint = ModelCheckpoint(\n","     filepath=checkpoint_filepath,\n","     save_weights_only=False,\n","     period=1)\n","\n","model.summary()"],"execution_count":23,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Model: \"encoder\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 224, 224, 32)      896       \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 224, 224, 64)      18496     \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 112, 112, 64)      36928     \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 56, 56, 128)       147584    \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 19, 19, 256)       590080    \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 19, 19, 15)        34575     \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 19, 19, 5)         680       \n","_________________________________________________________________\n","conv2d_transpose (Conv2DTran (None, 19, 19, 128)       5888      \n","_________________________________________________________________\n","up_sampling2d (UpSampling2D) (None, 38, 38, 128)       0         \n","_________________________________________________________________\n","conv2d_transpose_1 (Conv2DTr (None, 38, 38, 64)        73792     \n","_________________________________________________________________\n","conv2d_transpose_2 (Conv2DTr (None, 38, 38, 64)        36928     \n","_________________________________________________________________\n","up_sampling2d_1 (UpSampling2 (None, 76, 76, 64)        0         \n","_________________________________________________________________\n","conv2d_transpose_3 (Conv2DTr (None, 76, 76, 32)        18464     \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 76, 76, 3)         867       \n","_________________________________________________________________\n","up_sampling2d_2 (UpSampling2 (None, 152, 152, 3)       0         \n","=================================================================\n","Total params: 1,334,202\n","Trainable params: 1,334,202\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IWAqhThbLXUh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":442},"executionInfo":{"status":"error","timestamp":1595466442932,"user_tz":240,"elapsed":1257,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}},"outputId":"5276b61d-4023-47fe-e8c8-d23d447763d6"},"source":["train_dataGenerator = ImageDataGenerator(preprocessing_function=preprocess_input,\n","                                   width_shift_range=0.1,\n","                                   height_shift_range=0.1,\n","                                   zoom_range=0.1,\n","                                   channel_shift_range=0.1)\n","\n","valid_dataGenerator=ImageDataGenerator(preprocessing_function=preprocess_input)\n","\n","\n","batch_size = 32\n","trainGenerator = train_dataGenerator.flow_from_directory(\n","        root_dir+'/train/',\n","        target_size=(224, 224),\n","        batch_size= batch_size,\n","        class_mode= None, \n","        shuffle = False)\n","\n","testGenerator=valid_dataGenerator.flow_from_directory(\n","        root_dir+'/val/',\n","        target_size=(224, 224),\n","        batch_size= batch_size,\n","        class_mode= None, \n","        shuffle = False)"],"execution_count":24,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-30b407699de1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         shuffle = False)\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m testGenerator=valid_dataGenerator.flow_from_directory(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m         )\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Datasets/MODIS_MCD43A4/Globe/training_set/*/np_arrays/train/'"]}]},{"cell_type":"code","metadata":{"id":"PTwm6Y4MNeNi","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}