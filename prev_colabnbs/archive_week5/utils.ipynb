{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"utils.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPICn93RiALgQgNnOWd6B5q"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"982fpt10Tcvg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1595453367171,"user_tz":240,"elapsed":1515,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}},"outputId":"7f617863-b41b-4525-ade1-a58e9258c16a"},"source":["# Connect to Drive\n","from google.colab import drive\n","drive.mount(\"/content/gdrive\")\n","\n","# Verify the connection\n","!pwd\n","# !ls -lht gdrive/'Shared drives'/'2020_FDLUSA_Earth Science_Knowledge Discovery Framework'/Code/Datasets/UCMerced_LandUse/Images"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dtT1M_sbRnja","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595453370204,"user_tz":240,"elapsed":4273,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}},"outputId":"d51c23f6-63f4-4761-f62a-a3124a9c805f"},"source":["# Library Imports\n","import os\n","import time\n","import math\n","import pickle\n","import random\n","import tensorflow\n","import numpy as np\n","from numpy.linalg import norm\n","from tqdm import tqdm, tqdm_notebook\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n","from tensorflow.keras.applications.vgg16 import VGG16\n","from tensorflow.keras.applications.vgg19 import VGG19\n","from tensorflow.keras.applications.mobilenet import MobileNet\n","from tensorflow.keras.applications.inception_v3 import InceptionV3\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n","\n","# Custom Imports\n","!pip install import_ipynb\n","import import_ipynb"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: import_ipynb in /usr/local/lib/python3.6/dist-packages (0.1.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SyRJ0OWCPyg0","colab_type":"code","colab":{}},"source":["# Function to choose the predefined Model architecture\n","\n","def model_picker(name):\n","    if (name == 'vgg16'):\n","        model = VGG16(weights='imagenet',\n","                      include_top=False,\n","                      input_shape=(224, 224, 3),\n","                      pooling='max')\n","    elif (name == 'vgg19'):\n","        model = VGG19(weights='imagenet',\n","                      include_top=False,\n","                      input_shape=(224, 224, 3),\n","                      pooling='max')\n","    elif (name == 'mobilenet'):\n","        model = MobileNet(weights='imagenet',\n","                          include_top=False,\n","                          input_shape=(224, 224, 3),\n","                          pooling='max',\n","                          depth_multiplier=1,\n","                          alpha=1)\n","    elif (name == 'inception'):\n","        model = InceptionV3(weights='imagenet',\n","                            include_top=False,\n","                            input_shape=(224, 224, 3),\n","                            pooling='max')\n","    elif (name == 'resnet'):\n","        model = ResNet50(weights='imagenet',\n","                         include_top=False,\n","                         input_shape=(224, 224, 3),\n","                        pooling='max')\n","    elif (name == 'xception'):\n","        model = Xception(weights='imagenet',\n","                         include_top=False,\n","                         input_shape=(224, 224, 3),\n","                         pooling='max')\n","    else:\n","        print(\"Specified model not available\")\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GXD80cvUcAxr","colab_type":"code","colab":{}},"source":["extensions = ['.jpg', '.JPG', '.jpeg', '.JPEG', '.png', '.PNG', '.tif']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_tb-dDxuVdbQ","colab_type":"code","colab":{}},"source":["# Function to get the list of input file names\n","\n","def get_file_list(root_dir):\n","    file_list = []\n","    for root, directories, filenames in os.walk(root_dir):\n","        for filename in filenames:\n","            # print(\"filename:\", filename)\n","            if any(ext in filename for ext in extensions):\n","                file_list.append(os.path.join(root, filename))\n","    return file_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cAJtDWnpbmGp","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}