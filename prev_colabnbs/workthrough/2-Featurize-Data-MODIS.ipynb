{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2-Featurize-Data-MODIS.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"sV8t5w20uMRU","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"561rrpfX_VaY","colab_type":"text"},"source":["**Featurize Data**\n","\n","*Summary of this notebook:*  \n","Obtain a low-dimensional feature vector for each image in an input dataset using a ImageNet based pretrained model (MobileNet, here). Load the dataset in a generator object, preprocess based on the model, run predict on every image to obtain a feature vector. Save the feature vector and the filenames in a separate pickle file.\n","\n","*Definition of Done:*"]},{"cell_type":"code","metadata":{"id":"m5jn6I3fH4DW","colab_type":"code","colab":{}},"source":["import os\n","import tensorflow\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import math\n","import pickle\n","import rasterio\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PeVQm4uxJH9U","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594066422454,"user_tz":420,"elapsed":1133,"user":{"displayName":"Megs Seeley","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeqY758TVgaoy00y80vn5ecqtsvp3ePdkcZXg1=s64","userId":"04401323135423318197"}},"outputId":"c08cc5df-5d3b-4782-e9a4-cd856661b2e5"},"source":["from google.colab import drive \n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kWxOCMn_JRi7","colab_type":"code","colab":{}},"source":["os.chdir(\"/content/gdrive/Shared drives/2020_FDLUSA_Earth Science_Knowledge Discovery Framework/Code\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qjke8eMWh1Dt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594066440941,"user_tz":420,"elapsed":8505,"user":{"displayName":"Megs Seeley","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeqY758TVgaoy00y80vn5ecqtsvp3ePdkcZXg1=s64","userId":"04401323135423318197"}},"outputId":"3cb13a0a-95e5-4e3f-f944-0c5eeb6322f0"},"source":["tensorflow.test.gpu_device_name()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"xsFRSgptJ5jH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594066762074,"user_tz":420,"elapsed":1701,"user":{"displayName":"Megs Seeley","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeqY758TVgaoy00y80vn5ecqtsvp3ePdkcZXg1=s64","userId":"04401323135423318197"}},"outputId":"0a49eaf4-f6ba-4dd8-98e7-011bd38d9583"},"source":["## FIX\n","\n","dataset = \"training_set_tmp\"\n","dataPath = (\"Datasets/\" + dataset + \"/np_arrays\")\n","modelName = \"KDF_modis\"\n","files = os.listdir(dataPath)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['subset_5000_200_500.npy', 'subset_0_0_500.npy', 'subset_0_1000_500.npy']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UwuJB526Ykip","colab_type":"text"},"source":["Data Generator\n","1. Get input            : input_path -> image\n","2. Get output           : input_path -> label\n","3. Pre-process input    : image -> pre-processing step -> image\n","4. Get generator output : ( batch_input, batch_labels )\n"]},{"cell_type":"code","metadata":{"id":"mk_NI9YgoGL7","colab_type":"code","colab":{}},"source":["def get_input(path):\n","    \n","    img = load( path )\n","    \n","    return( img )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9KlKxFJCoFxu","colab_type":"code","colab":{}},"source":["def get_output( path, label_file = None ):\n","    \n","    img_id = path.split('/')[-1].split('.')[0]\n","    labels = label_file.loc[img_id].values\n","    \n","    return(labels)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UIBClyqwoGaK","colab_type":"code","colab":{}},"source":["def preprocess_input( image ):\n","    \n","    --- Rescale Image\n","    --- Rotate Image\n","    --- Resize Image\n","    --- Flip Image\n","    --- PCA etc.\n","    \n","    return( image )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XyVBHXGcoGYX","colab_type":"code","colab":{}},"source":["def image_generator(files, label_file, batch_size = 64):\n","    \n","    while True:\n","          # Select files (paths/indices) for the batch\n","          batch_paths  = np.random.choice(a = files, \n","                                          size = batch_size)\n","          batch_input  = []\n","          batch_output = [] \n","          \n","          # Read in each input, perform preprocessing and get labels\n","          for input_path in batch_paths:\n","              input = get_input(input_path )\n","              output = get_output(input_path,label_file=label_file )\n","            \n","              input = preprocess_input(image=input)\n","              batch_input += [ input ]\n","              batch_output += [ output ]\n","          # Return a tuple of (input, output) to feed the network\n","          batch_x = np.array( batch_input )\n","          batch_y = np.array( batch_output )\n","        \n","          yield( batch_x, batch_y )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hVUaVpzyzQEU","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LZE_TiT8zQBj","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dwxo28XdzP_y","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bUpdSc8dzP6R","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lB3dUQ-ZLKRy","colab_type":"code","colab":{}},"source":["dataGenerator = ImageDataGenerator(\n","    preprocessing_function = preprocess_input\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rb4ffx8UNWcM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593458480471,"user_tz":420,"elapsed":2557,"user":{"displayName":"Megs Seeley","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeqY758TVgaoy00y80vn5ecqtsvp3ePdkcZXg1=s64","userId":"04401323135423318197"}},"outputId":"143f33cb-74a9-4134-ac9c-8fd7ea137895"},"source":["batch_size = 32\n","trainGenerator = dataGenerator.flow_from_directory(\n","        dataPath,\n","        target_size=(224, 224),\n","        batch_size= batch_size,\n","        class_mode= None, \n","        shuffle = False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 2100 images belonging to 21 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pJlRYBY5YxQD","colab_type":"text"},"source":["Generate Feature Vector from User-defined dataset"]},{"cell_type":"code","metadata":{"id":"RGFfh6lJO1OZ","colab_type":"code","colab":{}},"source":["nImages = len(trainGenerator.filenames)\n","nLoops = int(math.ceil(nImages / batch_size))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NH0OQIKQQUQ8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593458968798,"user_tz":420,"elapsed":8662,"user":{"displayName":"Megs Seeley","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeqY758TVgaoy00y80vn5ecqtsvp3ePdkcZXg1=s64","userId":"04401323135423318197"}},"outputId":"eaf49556-b791-4ce6-d06f-7855b3188127"},"source":["bottleneckFeaturesTrain = model.predict(trainGenerator, nLoops, verbose = 1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["66/66 [==============================] - 8s 116ms/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qb7FWIunYJD2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593458977491,"user_tz":420,"elapsed":847,"user":{"displayName":"Megs Seeley","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeqY758TVgaoy00y80vn5ecqtsvp3ePdkcZXg1=s64","userId":"04401323135423318197"}},"outputId":"9b99d649-29f7-4aeb-9eca-1a8e73036473"},"source":["print(bottleneckFeaturesTrain.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(2100, 1024)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OWPalzfrggtv","colab_type":"text"},"source":["Dump features and filenames into GDrive folder\n"]},{"cell_type":"code","metadata":{"id":"zXQBlk5WecgV","colab_type":"code","colab":{}},"source":["pickle.dump(bottleneckFeaturesTrain, file = open((\"Features/\" + modelName + \"_\" + dataset + \"_features.pkl\"), mode = 'wb'))\n","pickle.dump(trainGenerator.filenames, file = open((\"Features/\" + modelName + \"_\" + dataset + \"_filenames.pkl\"), mode = 'wb'))"],"execution_count":null,"outputs":[]}]}