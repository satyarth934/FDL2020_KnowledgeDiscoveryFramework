{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2-Featurize-Data.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"sV8t5w20uMRU","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"561rrpfX_VaY","colab_type":"text"},"source":["**Featurize Data**\n","\n","*Summary of this notebook:*  \n","Obtain a low-dimensional feature vector for each image in an input dataset using a ImageNet based pretrained model (MobileNet, here). Load the dataset in a generator object, preprocess based on the model, run predict on every image to obtain a feature vector. Save the feature vector and the filenames in a separate pickle file.\n","\n","*Definition of Done:*"]},{"cell_type":"code","metadata":{"id":"m5jn6I3fH4DW","colab_type":"code","colab":{}},"source":["import os\n","import tensorflow\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import math\n","import pickle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PeVQm4uxJH9U","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593458478904,"user_tz":420,"elapsed":1245,"user":{"displayName":"Megs Seeley","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeqY758TVgaoy00y80vn5ecqtsvp3ePdkcZXg1=s64","userId":"04401323135423318197"}},"outputId":"2606ba85-42d2-4cc8-b194-f7ec4d099f0f"},"source":["from google.colab import drive \n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kWxOCMn_JRi7","colab_type":"code","colab":{}},"source":["os.chdir(\"/content/gdrive/Shared drives/2020_FDLUSA_Earth Science_Knowledge Discovery Framework/Code\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qjke8eMWh1Dt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593458540599,"user_tz":420,"elapsed":791,"user":{"displayName":"Megs Seeley","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeqY758TVgaoy00y80vn5ecqtsvp3ePdkcZXg1=s64","userId":"04401323135423318197"}},"outputId":"426b9daf-1a3c-4cf2-b28f-5ab8d272574a"},"source":["tensorflow.test.gpu_device_name()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"xsFRSgptJ5jH","colab_type":"code","colab":{}},"source":["dataset = \"UCMerced_LandUse\"\n","dataPath = (\"Datasets/\"+ dataset+ \"/Images\")\n","modelName = \"MobileNet\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0W7RiXQmNinE","colab_type":"text"},"source":["Import Model\n"]},{"cell_type":"code","metadata":{"id":"ismae6RKRZbf","colab_type":"code","colab":{}},"source":["# Import pretrained model\n","\n","from tensorflow.keras.applications import MobileNet\n","from tensorflow.keras.applications.mobilenet import preprocess_input\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xxj8mD_2XrWK","colab_type":"code","colab":{}},"source":["model = MobileNet(\n","    input_shape = (224, 224, 3),\n","    include_top = False,\n","    weights = 'imagenet',\n","    pooling = \"max\"\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UwuJB526Ykip","colab_type":"text"},"source":["Get Data & Preprocess"]},{"cell_type":"code","metadata":{"id":"lB3dUQ-ZLKRy","colab_type":"code","colab":{}},"source":["dataGenerator = ImageDataGenerator(\n","    preprocessing_function = preprocess_input\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rb4ffx8UNWcM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593458480471,"user_tz":420,"elapsed":2557,"user":{"displayName":"Megs Seeley","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeqY758TVgaoy00y80vn5ecqtsvp3ePdkcZXg1=s64","userId":"04401323135423318197"}},"outputId":"143f33cb-74a9-4134-ac9c-8fd7ea137895"},"source":["batch_size = 32\n","trainGenerator = dataGenerator.flow_from_directory(\n","        dataPath,\n","        target_size=(224, 224),\n","        batch_size= batch_size,\n","        class_mode= None, \n","        shuffle = False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 2100 images belonging to 21 classes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pJlRYBY5YxQD","colab_type":"text"},"source":["Generate Feature Vector from User-defined dataset"]},{"cell_type":"code","metadata":{"id":"RGFfh6lJO1OZ","colab_type":"code","colab":{}},"source":["nImages = len(trainGenerator.filenames)\n","nLoops = int(math.ceil(nImages / batch_size))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NH0OQIKQQUQ8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593458968798,"user_tz":420,"elapsed":8662,"user":{"displayName":"Megs Seeley","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeqY758TVgaoy00y80vn5ecqtsvp3ePdkcZXg1=s64","userId":"04401323135423318197"}},"outputId":"eaf49556-b791-4ce6-d06f-7855b3188127"},"source":["bottleneckFeaturesTrain = model.predict(trainGenerator, nLoops, verbose = 1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["66/66 [==============================] - 8s 116ms/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qb7FWIunYJD2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593458977491,"user_tz":420,"elapsed":847,"user":{"displayName":"Megs Seeley","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgeqY758TVgaoy00y80vn5ecqtsvp3ePdkcZXg1=s64","userId":"04401323135423318197"}},"outputId":"9b99d649-29f7-4aeb-9eca-1a8e73036473"},"source":["print(bottleneckFeaturesTrain.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(2100, 1024)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OWPalzfrggtv","colab_type":"text"},"source":["Dump features and filenames into GDrive folder\n"]},{"cell_type":"code","metadata":{"id":"zXQBlk5WecgV","colab_type":"code","colab":{}},"source":["pickle.dump(bottleneckFeaturesTrain, file = open((\"Features/\" + modelName + \"_\" + dataset + \"_features.pkl\"), mode = 'wb'))\n","pickle.dump(trainGenerator.filenames, file = open((\"Features/\" + modelName + \"_\" + dataset + \"_filenames.pkl\"), mode = 'wb'))"],"execution_count":null,"outputs":[]}]}