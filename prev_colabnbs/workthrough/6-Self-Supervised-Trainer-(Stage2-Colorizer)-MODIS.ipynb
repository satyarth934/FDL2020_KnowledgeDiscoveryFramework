{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"6-Self-Supervised-Trainer-(Stage2-Colorizer)-MODIS.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"561rrpfX_VaY","colab_type":"text"},"source":["**GET DATA**\n","\n","Summary of this notebook: ...\n","\n","Todo:\n","\n","1. Self supervised representation learning using colorization as a pretext task\n","2. Taking in an image I , rotating it by an a set angle A--> rotated image (I_A), rotated angle A (actual label) (Done)\n","3. Dataloader that does this somehow (Done)\n","4. Some model-> ResNet50  + new full-connected layer (feature vector-> probability that image belongs to one of n classes) (Done-ish)\n","5. Additional training with the above model minimizing the loss wrt. actual rotated angle\n","f(I_A)=min[L(A_predict,A)]\n","6. Save this new model\n","\n","7. Proof of concept:\n","Imagenet-> Train on Caltech validation on caltech\n","\n","\n","\n","\n","Definition of Done: ..."]},{"cell_type":"markdown","metadata":{"id":"6Ev8fWuVejb0","colab_type":"text"},"source":["# Imports\n"]},{"cell_type":"code","metadata":{"id":"z81q60U3G0ol","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1594341787109,"user_tz":420,"elapsed":909,"user":{"displayName":"Nishan Srishankar","photoUrl":"","userId":"11074479106454986489"}},"outputId":"a8d65998-db4a-4204-df08-4d7b2675e6b5"},"source":["# Mount Google drive\n","from google.colab import drive\n","import os\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YgicpEBiG2d8","colab_type":"code","colab":{}},"source":["# Change to current dataset\n","os.chdir(\"/content/gdrive/Shared drives/2020_FDLUSA_Earth Science_Knowledge Discovery Framework/Code\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TKfFt17nGyDm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594341793046,"user_tz":420,"elapsed":6820,"user":{"displayName":"Nishan Srishankar","photoUrl":"","userId":"11074479106454986489"}},"outputId":"13899606-7014-4e87-f39f-74d57bb972dd"},"source":["# Imports from Colab 2\n","import math\n","import numpy as np\n","import pickle\n","import keras\n","import tensorflow\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from datetime import datetime\n","# Import pretrained model\n","from tensorflow.keras.applications import MobileNet, ResNet50\n","from tensorflow.keras.applications.resnet50 import preprocess_input"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"gFkitrY7HMwz","colab_type":"code","colab":{}},"source":["# Imports for Colab 6\n","import cv2 # Read raw image\n","import glob\n","from google.colab.patches import cv2_imshow\n","from matplotlib import pyplot as plt\n","from scipy import ndimage # For rotation task or\n","import imutils\n","from tensorflow.keras import Model\n","from tensorflow.keras.layers import Dense, Flatten, Dropout\n","from tensorflow.keras.optimizers import Adam\n","\n","from tensorflow.python.keras.utils import data_utils\n","from tensorflow.keras.preprocessing.image import Iterator\n","\n","\n","# Imports for Colorizer\n","from os import path\n","from tensorflow.keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, AveragePooling2D, Reshape, Conv2DTranspose, ZeroPadding2D\n","from tensorflow.keras.layers import Activation, InputLayer, BatchNormalization\n","from tensorflow.keras.callbacks import TensorBoard\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n","from skimage.io import imsave\n","import random\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7AX-W5mqG4xD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594341803200,"user_tz":420,"elapsed":9374,"user":{"displayName":"Nishan Srishankar","photoUrl":"","userId":"11074479106454986489"}},"outputId":"3330cf16-2811-44eb-b670-e3baa33835ac"},"source":["# Check to see if GPU is being used\n","tensorflow.test.gpu_device_name()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"KzmeP_R9ep5w","colab_type":"text"},"source":["# Data Augmentation/Analysis"]},{"cell_type":"code","metadata":{"id":"n2rPBilY_w-X","colab_type":"code","colab":{}},"source":["# Raw dataset/path/model paths\n","dataset= \"Datasets/MODIS_MCD43A4/Globe/training_set/\"\n","# dataset = \"MODIS_MCD43A4/Globe/training_set/2020169\"\n","# dataset = \"MODIS_MCD43A4/Globe/training_set/2020051\"\n","dataPath = dataset + \"*/np_arrays\"\n","modelName = \"KDF_modis\"\n","\n","image_globs=glob.glob(dataPath+'/*.npy')\n","\n","val_ratio=int(0.1*len(image_globs))\n","\n","\n","val_image_globs=image_globs[:val_ratio]\n","train_image_globs=image_globs[val_ratio:]\n","# val_image_globs=glob.glob(dataPath+'/*.npy')\n","\n","# # JUST CHECKING\n","# for f in train_image_globs:\n","#   image = np.expand_dims(np.load(f)/255., 0)\n","#   image = np.swapaxes(image, 0, -1)\n","#   if np.sum(image.shape) < (1+500+500+3):\n","#     continue\n","#   print(image.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"00-7YfN5ADAy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":73},"executionInfo":{"status":"ok","timestamp":1594341920677,"user_tz":420,"elapsed":1054,"user":{"displayName":"Nishan Srishankar","photoUrl":"","userId":"11074479106454986489"}},"outputId":"0b6db143-b2ba-4d05-baa9-bf07bb747809"},"source":["print(len(train_image_globs))\n","print(train_image_globs[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["19246\n","Datasets/MODIS_MCD43A4/Globe/training_set/2020051/np_arrays/MCD43A4.A2020051.h25v05.006.2020062235616_1200_800_400.npy\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FNBiKT_Qe0xr","colab_type":"text"},"source":["# Dataloader creation and test"]},{"cell_type":"code","metadata":{"id":"cnwO8mvVvWFT","colab_type":"code","colab":{}},"source":["# dims=(500,500,3)\n","dims=(400,400,3)\n","bool_generate=False\n","# X_train=np.empty((0,*dims))\n","# chunk_prefix='Datasets/MODIS_MCD43A4/Globe/training_set/chunks/'\n","\n","# if bool_generate:\n","#   for i,f in enumerate(train_image_globs):\n","#     # image=np.expand_dims(img_to_array(load_img(f,target_size=dims))/255.,0)\n","#     image = np.expand_dims(np.load(f),0)\n","#     image = np.resize(image, (1,*dims))\n","#     X_train=np.vstack((X_train,image))\n","#     if i!=len(train_image_globs):\n","#       # print(i)\n","#       if (i%100)==0:\n","#         chunk_fname=chunk_prefix+'modis_xtrain_{}.npy'.format(str((i)//100))\n","#         with open(chunk_fname,'wb') as f:\n","#           np.save(f,X_train,allow_pickle=True)\n","#         print(\"Chunk {} done\".format((i)//100))\n","#         X_train=np.empty((0,*dims))\n","#     else:\n","#       chunk_fname=chunk_prefix+'modis_xtrain_{}.npy'.format(str(np.ceil((i)/100)))\n","#       with open(chunk_fname,'wb') as f:\n","#         np.save(f,X_train,allow_pickle=True)\n","#       print(\"Chunk {} done\".format(np.ceil((i)/100)))\n","# else:\n","  \n","#   for f in glob.glob(chunk_prefix+'*.npy'):\n","#     chunk_data=np.load(f)\n","#     if len(chunk_data)==100 or f.split('/')[-1].endswith('214.npy'):\n","#       X_train=np.vstack((X_train,chunk_data))\n","#     else:\n","#       print(\"Skipping: \",f)\n","\n","\n","# train_name='modis231561_xtrain.npy'\n","# test_name='modis231561_xtest.npy'\n","\n","# if path.exists(train_name):\n","#   print(\"Train exists\")\n","#   X_train=np.load(train_name)\n","# else:\n","#   X_train=np.empty((0,*dims))\n","\n","#   for f in train_image_globs:\n","#     # image=np.expand_dims(img_to_array(load_img(f,target_size=dims))/255.,0)\n","#     image = np.expand_dims(np.load(f),0)\n","#     image = np.resize(image, (1, 400, 400, 3))\n","#     if np.sum(image.shape) < (1+400+400+3):\n","#       continue\n","#     # print(image[1,0,0,0])\n","#     # print(np.mean(image[1,:,:,0]))\n","#     # if image[0,0,0,0]!=np.mean(image[0,:,:,0]):\n","#     print(image.shape, X_train.shape)\n","#     X_train=np.vstack((X_train,image))\n","\n","#     if len(X_train)%100:\n","#       chunk_fname=f'modis_xtrain_{str(len(X_train)%100)}'.npy\n","#       with open(chunk_fname) as f:\n","#         np.save(f,X_train,allow_pickle=True)\n","  \n","  # with open(train_name, 'wb') as f:\n","  #   np.save(f,X_train,allow_pickle=True)\n","  \n","# if path.exists(test_name):\n","#   print(\"Test exists\")\n","#   X_test=np.load(test_name)\n","# else:\n","#   X_test=np.empty((0,*dims))\n","\n","#   for f in val_image_globs:\n","#     image = np.expand_dims(np.load(f)/255.,0)\n","#     image = np.resize(image, (1, 512, 512, 3))\n","#     if np.sum(image.shape) < (1+512+512+3):\n","#       continue\n","#     X_test=np.vstack((X_test,image))\n","\n","  # with open(test_name, 'wb') as f:\n","  #   np.save(f,X_test,allow_pickle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D06E6yTh03Hf","colab_type":"code","colab":{}},"source":["\n","# class DataGenerator(data_utils.Sequence):\n","#     'Generates data for Keras'\n","#     def __init__(self, list_IDs, batch_size=32, dim=(246,246,3),\n","#                  n_classes=4, shuffle=True):\n","#         'Initialization'\n","#         self.dim = dim\n","#         self.batch_size = batch_size\n","#         self.list_IDs = list_IDs\n","#         self.shuffle = shuffle\n","#         self.on_epoch_end()\n","\n","#     def __len__(self):\n","#         'Denotes the number of batches per epoch'\n","#         return int(np.floor(len(self.list_IDs) / self.batch_size))\n","\n","#     def __getitem__(self, index):\n","#         'Generate one batch of data'\n","#         # Generate indexes of the batch\n","#         indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","\n","#         # Find list of IDs\n","#         list_IDs_temp = [self.list_IDs[k] for k in indexes]\n","\n","#         # Generate data\n","#         X= self.__data_generation(list_IDs_temp)\n","\n","#         return X, y\n","\n","#     def on_epoch_end(self):\n","#         'Updates indexes after each epoch'\n","#         self.indexes = np.arange(len(self.list_IDs))\n","#         if self.shuffle == True:\n","#             np.random.shuffle(self.indexes)\n","\n","#     def __data_generation(self, list_IDs_temp):\n","#         'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n","#         # Initialization\n","#         X = np.empty((self.batch_size, *self.dim))\n","#         # y = np.empty((self.batch_size), dtype=int)\n","#         # for i in range(len(list_IDs_temp)): \n","#         #   temp_image=cv2.imread(list_IDs_temp[i])\n","#         #   h,w,_=temp_image.shape\n","#         #   angle_categorical=np.random.randint(low=0,high=4) # 0,1,2,3\n","#         #   angle=angle_categorical*90\n","#         #   rotated_image=rotate_image(temp_image,angle)\n","\n","#         #   image_rotated_cropped = crop_around_center(\n","#         #     rotated_image,\n","#         #     *largest_rotated_rect(\n","#         #         w,\n","#         #         h,\n","#         #         math.radians(angle)\n","#         #     )\n","#         #   )\n","#         #   h,w,_=image_rotated_cropped.shape\n","#         #   center=(h//2,w//2)\n","#         #   d_h=246\n","#         #   X[i,]= image_rotated_cropped[int(center[0]-d_h/2):int(center[0]+d_h/2), int(center[1]-d_h/2):int(center[1]+d_h/2)]\n","#         #   y[i]=angle_categorical\n","\n","#         return X"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kt6oH37M-_VN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594341928369,"user_tz":420,"elapsed":1651,"user":{"displayName":"Nishan Srishankar","photoUrl":"","userId":"11074479106454986489"}},"outputId":"2e23d584-b37f-4e92-ca65-e8115464bba9"},"source":["# train_dataGenerator = ImageDataGenerator(rotation_range=20,\n","#                                    width_shift_range=0.1,\n","#                                    height_shift_range=0.1,\n","#                                    zoom_range=0.1,\n","#                                    horizontal_flip=True)\n","\n","batch_size = 32\n","\n","class CustomDataGenerator(data_utils.Sequence):\n","    'Generates data for Keras'\n","    def __init__(self, list_IDs, batch_size=batch_size, dim=(400,400,3), shuffle=True):\n","        'Initialization'\n","        self.dim = dim\n","        self.batch_size = batch_size\n","        self.list_IDs = list_IDs\n","        self.shuffle = shuffle\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        return int(np.floor(len(self.list_IDs) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","\n","        # Find list of IDs\n","        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n","\n","        # Generate data\n","        X,y= self.__data_generation(list_IDs_temp)\n","        #print(X.shape,y.shape)\n","        return X, y\n","\n","    def on_epoch_end(self):\n","        'Updates indexes after each epoch'\n","        self.indexes = np.arange(len(self.list_IDs))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generation(self, list_IDs_temp):\n","        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n","        # Initialization\n","        X = np.empty((self.batch_size, *self.dim))\n","        for i,f in enumerate(list_IDs_temp):\n","            X[i,]=np.load(f)\n","\n","        gray_batch=rgb2gray(X)\n","\n","        X_batch=gray_batch[:,:,:]/255. #(16,400,400)\n","        X_batch=np.repeat(np.expand_dims(X_batch,3),3,axis=3)\n","        Y_batch=X[:,:,:,:]/255.\n","        return X_batch,Y_batch\n","\n","print(\"LEN TRAINING:\",len(train_image_globs))\n","train_dataGenerator=CustomDataGenerator(train_image_globs)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["LEN TRAINING: 19246\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ri-SDcocunWM","colab_type":"code","colab":{}},"source":["# def image_a_b_gen(batch_size):\n","#     for batch in train_dataGenerator.flow(X_train, batch_size=batch_size):\n","#         gray_batch = rgb2gray(batch)\n","        \n","#         X_batch = gray_batch[:,:,:]/255.\n","#         Y_batch = batch[:,:,:,:]/255.\n","#         print(np.max(X_batch),np.min(X_batch),np.max(Y_batch),np.min(Y_batch))\n","#         yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch)\n","\n","# dataset= \"Datasets/MODIS_MCD43A4/Globe/training_set/\"\n","# def image_a_b_gen(batch_size):\n","#     for batch in train_dataGenerator.flow_from_directory(dataset+'2020169/', \n","#                                                           batch_size=batch_size,\n","#                                                           target_size=(400, 400),\n","#                                                           color_mode=\"rgb\",\n","#                                                           class_mode=\"input\",\n","#                                                           shuffle=True,\n","#                                                           seed=42\n","#                                                           ):\n","#         gray_batch = rgb2gray(batch[0])\n","        \n","#         X_batch = gray_batch[:,:,:]/255.# Gray\n","#         Y_batch = batch[0][:,:,:,:]/255. # RGB\n","#         print(np.max(X_batch),np.min(X_batch),np.max(Y_batch),np.min(Y_batch))\n","#         yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1QAgBBBNfDAx","colab_type":"text"},"source":["# Model creation"]},{"cell_type":"code","metadata":{"id":"6S5QVLNOUDLV","colab_type":"code","colab":{}},"source":["model = Sequential()\n","# model.add(InputLayer(input_shape=(256, 256, 1)))\n","model.add(InputLayer(input_shape=(400, 400, 3)))\n","model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n","# model.add(AveragePooling2D(pool_size=(2,2),padding='valid'))\n","model.add(AveragePooling2D(pool_size=(3,3),padding='valid'))\n","model.add(Conv2D(32, (3, 3), activation='relu', padding='same', strides=2))\n","# model.add(AveragePooling2D(pool_size=(2,2),padding='valid'))\n","model.add(AveragePooling2D(pool_size=(3,3),padding='valid'))\n","model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n","# model.add(AveragePooling2D(pool_size=(3,3),padding='valid'))\n","# model.add(AveragePooling2D(pool_size=(2,2),padding='valid'))\n","model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))\n","# model.add(AveragePooling2D(pool_size=(3,3),padding='valid'))\n","model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n","# model.add(AveragePooling2D(pool_size=(3,3),padding='valid'))\n","model.add(Conv2D(128, (3, 3), activation='relu', padding='same', strides=2))\n","model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n","model.add(UpSampling2D((2, 2)))\n","model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n","model.add(UpSampling2D((2, 2)))\n","model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n","model.add(UpSampling2D((2, 2))) # extra\n","# model.add(UpSampling2D((3, 3))) # extra\n","model.add(ZeroPadding2D((1, 1))) # extra\n","model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n","# model.add(Conv2D(64, (3, 3), activation='relu', padding='valid'))\n","model.add(UpSampling2D((2, 2))) # extra\n","model.add(UpSampling2D((2, 2))) # extra\n","model.add(Conv2D(3, (3, 3), activation='tanh', padding='same'))\n","model.add(UpSampling2D((2, 2)))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tsgBqD4dfHoE","colab_type":"text"},"source":["# Model Training"]},{"cell_type":"code","metadata":{"id":"LoPPvZ9Gkm7_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":984},"executionInfo":{"status":"ok","timestamp":1594342439442,"user_tz":420,"elapsed":801,"user":{"displayName":"Nishan Srishankar","photoUrl":"","userId":"11074479106454986489"}},"outputId":"9d6e9e47-569c-42c9-9b47-25358b4b1970"},"source":["# model.compile(optimizer='rmsprop', loss='mse', metrics = ['accuracy'])\n","# model.compile(optimizer='adadelta',loss='binary_crossentropy',metrics=['accuracy'])\n","\n","\n","from keras import backend as K\n","def f1(y_true, y_pred):\n","    y_pred = K.round(y_pred)\n","    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n","    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n","    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n","    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n","\n","    p = tp / (tp + fp + K.epsilon())\n","    r = tp / (tp + fn + K.epsilon())\n","\n","    f1 = 2*p*r / (p+r+K.epsilon())\n","    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n","    return K.mean(f1)\n","\n","def f1_loss(y_true, y_pred):\n","    \n","    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n","    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n","    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n","    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n","\n","    p = tp / (tp + fp + K.epsilon())\n","    r = tp / (tp + fn + K.epsilon())\n","\n","    f1 = 2*p*r / (p+r+K.epsilon())\n","    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n","    return 1 - K.mean(f1)\n","\n","model.compile(optimizer='adam',loss=[tf.keras.losses.BinaryCrossentropy(),f1_loss],loss_weights=[0.5, 0.5],metrics=['accuracy',f1,tf.keras.metrics.BinaryCrossentropy()])\n","\n","callback_earlystop=EarlyStopping(monitor='loss',patience=5)\n","\n","checkpoint_filepath = 'Models/checkpoint/model2_{epoch:04d}.h5'\n","callback_checkpoint = ModelCheckpoint(\n","     filepath=checkpoint_filepath,\n","     save_weights_only=False,\n","     period=1)\n","\n","\n","\n","# checkpoint_filepath = '/tmp/checkpoint'\n","# callback_checkpoint = ModelCheckpoint(\n","#     filepath=checkpoint_filepath,\n","#     save_weights_only=False,\n","#     monitor='train_acc',\n","#     mode='max',\n","#     save_best_only=True)\n","\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 400, 400, 32)      896       \n","_________________________________________________________________\n","average_pooling2d (AveragePo (None, 133, 133, 32)      0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 67, 67, 32)        9248      \n","_________________________________________________________________\n","average_pooling2d_1 (Average (None, 22, 22, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 22, 22, 64)        18496     \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 11, 11, 64)        36928     \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 11, 11, 128)       73856     \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 6, 6, 128)         147584    \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 6, 6, 256)         295168    \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 6, 6, 256)         590080    \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 6, 6, 128)         295040    \n","_________________________________________________________________\n","up_sampling2d (UpSampling2D) (None, 12, 12, 128)       0         \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 12, 12, 128)       147584    \n","_________________________________________________________________\n","up_sampling2d_1 (UpSampling2 (None, 24, 24, 128)       0         \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 24, 24, 64)        73792     \n","_________________________________________________________________\n","up_sampling2d_2 (UpSampling2 (None, 48, 48, 64)        0         \n","_________________________________________________________________\n","zero_padding2d (ZeroPadding2 (None, 50, 50, 64)        0         \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 50, 50, 64)        36928     \n","_________________________________________________________________\n","up_sampling2d_3 (UpSampling2 (None, 100, 100, 64)      0         \n","_________________________________________________________________\n","up_sampling2d_4 (UpSampling2 (None, 200, 200, 64)      0         \n","_________________________________________________________________\n","conv2d_12 (Conv2D)           (None, 200, 200, 3)       1731      \n","_________________________________________________________________\n","up_sampling2d_5 (UpSampling2 (None, 400, 400, 3)       0         \n","=================================================================\n","Total params: 1,727,331\n","Trainable params: 1,727,331\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YdOe_DrN625Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":627},"executionInfo":{"status":"ok","timestamp":1594352025233,"user_tz":420,"elapsed":9581530,"user":{"displayName":"Nishan Srishankar","photoUrl":"","userId":"11074479106454986489"}},"outputId":"3b37e73f-0c5e-41bb-a5f0-066427543265"},"source":["model.fit_generator(train_dataGenerator,\n","                    epochs=20,\n","                    steps_per_epoch=len(train_image_globs)/batch_size,\n","                    callbacks=[callback_earlystop,callback_checkpoint],\n","                    use_multiprocessing=True,\n","                    workers=6,\n","                    max_queue_size=10)\n","\n","# model.fit(image_a_b_gen(batch_size),\n","#                     epochs=40,\n","#                     steps_per_epoch=len(train_image_globs)/batch_size,\n","#                     callbacks=[callback_earlystop,callback_checkpoint])\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","601/601 [============================>.] - ETA: 0s - loss: -619.4474 - accuracy: 0.8038 - f1: 1.9731 - binary_crossentropy: -1238.8949WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","602/601 [==============================] - 1197s 2s/step - loss: -619.4330 - accuracy: 0.8037 - f1: 1.9731 - binary_crossentropy: -1238.8661\n","Epoch 2/20\n","WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","600/601 [============================>.] - ETA: 2s - loss: -620.9251 - accuracy: 0.8056 - f1: 1.9756 - binary_crossentropy: -1241.8481WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","602/601 [==============================] - 1164s 2s/step - loss: -620.8271 - accuracy: 0.8054 - f1: 1.9756 - binary_crossentropy: -1241.6522\n","Epoch 3/20\n","WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","600/601 [============================>.] - ETA: 2s - loss: -621.0225 - accuracy: 0.8056 - f1: 1.9756 - binary_crossentropy: -1242.0450WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","602/601 [==============================] - 1186s 2s/step - loss: -621.0347 - accuracy: 0.8056 - f1: 1.9756 - binary_crossentropy: -1242.0695\n","Epoch 4/20\n","WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","600/601 [============================>.] - ETA: 2s - loss: -620.7675 - accuracy: 0.8056 - f1: 1.9756 - binary_crossentropy: -1241.5354WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","602/601 [==============================] - 1182s 2s/step - loss: -620.8006 - accuracy: 0.8054 - f1: 1.9756 - binary_crossentropy: -1241.6017\n","Epoch 5/20\n","WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","600/601 [============================>.] - ETA: 2s - loss: -620.7502 - accuracy: 0.8056 - f1: 1.9756 - binary_crossentropy: -1241.5006WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","602/601 [==============================] - 1174s 2s/step - loss: -620.8535 - accuracy: 0.8057 - f1: 1.9756 - binary_crossentropy: -1241.7070\n","Epoch 6/20\n","WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","600/601 [============================>.] - ETA: 2s - loss: -621.0161 - accuracy: 0.8055 - f1: 1.9756 - binary_crossentropy: -1242.0310WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","602/601 [==============================] - 1162s 2s/step - loss: -621.0278 - accuracy: 0.8056 - f1: 1.9756 - binary_crossentropy: -1242.0546\n","Epoch 7/20\n","WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","600/601 [============================>.] - ETA: 2s - loss: -621.1617 - accuracy: 0.8059 - f1: 1.9756 - binary_crossentropy: -1242.3241WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","602/601 [==============================] - 1181s 2s/step - loss: -620.9989 - accuracy: 0.8056 - f1: 1.9756 - binary_crossentropy: -1241.9985\n","Epoch 8/20\n","WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","600/601 [============================>.] - ETA: 2s - loss: -620.8495 - accuracy: 0.8056 - f1: 1.9756 - binary_crossentropy: -1241.7001WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n","602/601 [==============================] - 1187s 2s/step - loss: -621.0062 - accuracy: 0.8056 - f1: 1.9756 - binary_crossentropy: -1242.0135\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f852b6d0438>"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"HuNpwqghIhOr","colab_type":"code","colab":{}},"source":["now = datetime.now()\n","dt_string = now.strftime(\"%d_%m_%H_%M\")\n","print(dt_string)\n","model.save('Models/Colorization_MODIS_Exp_Custom_' + dt_string)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AoNBrpVzOxWJ","colab_type":"text"},"source":["## Model Testing"]},{"cell_type":"code","metadata":{"id":"ns2CZFPpO0tR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1594140830222,"user_tz":420,"elapsed":5432,"user":{"displayName":"Nishan Srishankar","photoUrl":"","userId":"11074479106454986489"}},"outputId":"24da566c-6a46-4ccf-d905-e65880e30e81"},"source":["# X_test_m = rgb2gray(X_train)[:,:,:]\n","# X_test_m = X_test_m.reshape(X_test_m.shape+(1,))\n","# Y_test = (X_train)[:,:,:,:]\n","# Y_test = Y_test / 255.\n","# print(model.evaluate(X_test_m, Y_test, batch_size=batch_size))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["3/3 [==============================] - 1s 240ms/step - loss: 0.3335 - accuracy: 0.9058\n","[0.33350008726119995, 0.9057626724243164]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jSJP17H2P5yr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":305},"executionInfo":{"status":"ok","timestamp":1594141168628,"user_tz":420,"elapsed":1126,"user":{"displayName":"Nishan Srishankar","photoUrl":"","userId":"11074479106454986489"}},"outputId":"be0123af-4447-4cd8-942e-1331044658fb"},"source":["# # while True:\n","# rand_index=np.random.randint(0,len(train_image_globs))\n","# print(rand_index,train_image_globs[rand_index])\n","# sample_image = np.expand_dims(np.load(train_image_globs[rand_index])/255.,0)\n","# # if np.sum(sample_image.shape) == (1+500+500+3):\n","# #   continue\n","# sample_image = np.resize(sample_image, (1, 512, 512, 3))\n","\n","# # sample_image=img_to_array(load_img(val_image_globs[rand_index]))\n","# # sample_image=np.expand_dims(sample_image/255.,0)\n","\n","# sample_image_x=rgb2gray(sample_image)[:,:,:]\n","# sample_image_x=sample_image_x.reshape(sample_image_x.shape+(1,))\n","\n","# # Test model\n","# output = model.predict(sample_image_x)\n","# # output = output * 255.\n","\n","# # Output colorizations\n","# for i in range(len(output)):\n","#     # cur = np.zeros((512, 512, 3))\n","#     # cur[:,:,0] = sample_image_x[i][:,:,0]\n","#     cur[:,:,0:] = output[i]\n","#     # imsave(\"Models/colorization_out/img_\"+str(rand_index)+ dt_string + \".png\", gray2rgb(cur))\n","#     # imsave(\"Models/colorization_out/raw_img_\"+str(rand_index)+ dt_string +\".png\",np.squeeze(sample_image))\n","\n","#     plt.imshow(cur)\n","#     plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"],"name":"stderr"},{"output_type":"stream","text":["23 ./Datasets/training_set_tmp2/2004031/np_arrays/MCD43A4.A2004031.h21v11.006.2016112020923_1344_2240_448.npy\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"wHq_qPhkK2VE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594141113963,"user_tz":420,"elapsed":959,"user":{"displayName":"Nishan Srishankar","photoUrl":"","userId":"11074479106454986489"}},"outputId":"9bf3f080-507c-42a6-ccef-89557969784d"},"source":["# np.max(sample_image)\n","# # np.min(output)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["128.49803921568628"]},"metadata":{"tags":[]},"execution_count":29}]}]}