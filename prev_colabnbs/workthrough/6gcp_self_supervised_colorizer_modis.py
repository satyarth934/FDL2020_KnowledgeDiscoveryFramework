# -*- coding: utf-8 -*-
"""6-Self-Supervised-Trainer-(Stage2-Colorizer)-MODIS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MV7E4F5PlMVzjHxXYI5RI-YhiBLB4e6p

**GET DATA**

Summary of this notebook: ...

Todo:

1. Self supervised representation learning using colorization as a pretext task
2. Taking in an image I , rotating it by an a set angle A--> rotated image (I_A), rotated angle A (actual label) (Done)
3. Dataloader that does this somehow (Done)
4. Some model-> ResNet50  + new full-connected layer (feature vector-> probability that image belongs to one of n classes) (Done-ish)
5. Additional training with the above model minimizing the loss wrt. actual rotated angle
f(I_A)=min[L(A_predict,A)]
6. Save this new model

7. Proof of concept:
Imagenet-> Train on Caltech validation on caltech




Definition of Done: ...

# Imports
"""

# # Mount Google drive
# from google.colab import drive
# import os
# drive.mount('/content/gdrive')

# Change to current dataset
import os
import sys
# sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')

# Imports from Colab 2
import math
import numpy as np
import pickle
import keras
import tensorflow
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from datetime import datetime
# Import pretrained model
from tensorflow.keras.applications import MobileNet, ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input

# Imports for Colab 6
import cv2 # Read raw image
import glob
# from google.colab.patches import cv2_imshow
from matplotlib import pyplot as plt
from scipy import ndimage # For rotation task or
import imutils
from tensorflow.keras import Model
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.optimizers import Adam

from tensorflow.python.keras.utils import data_utils
from tensorflow.keras.preprocessing.image import Iterator


# Imports for Colorizer
from os import path
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, AveragePooling2D, Reshape, Conv2DTranspose, ZeroPadding2D
from tensorflow.keras.layers import Activation, InputLayer, BatchNormalization
from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb
from skimage.io import imsave
import random
import tensorflow as tf

# Check to see if GPU is being used
tensorflow.test.gpu_device_name()

"""# Data Augmentation/Analysis"""

# Raw dataset/path/model paths
# dataset= "datasets/training_set/"
dataset = "Datasets/MODIS_MCD43A4/Globe/training_set/"
# dataset = "MODIS_MCD43A4/Globe/training_set/2020169"
# dataset = "MODIS_MCD43A4/Globe/training_set/2020051"
dataPath = dataset
modelName = "KDF_modis"

print(os.path.abspath(os.curdir))
print(os.listdir("."))

image_globs=glob.glob(dataPath+'*/np_arrays/*.npy')
print(len(image_globs))
print("-----------------------------------------------------------------------------")

val_ratio=int(0.1*len(image_globs))

val_image_globs=image_globs[:val_ratio]
train_image_globs=image_globs[val_ratio:]

# val_image_globs=glob.glob(dataPath+'/*.npy')

print(len(train_image_globs))
print(train_image_globs[0])

"""# Dataloader creation and test"""

# dims=(500,500,3)
dims=(400,400,3)
bool_generate=False
# X_train=np.empty((0,*dims))
# chunk_prefix='Datasets/MODIS_MCD43A4/Globe/training_set/chunks/'


# train_dataGenerator = ImageDataGenerator(rotation_range=20,
#                                    width_shift_range=0.1,
#                                    height_shift_range=0.1,
#                                    zoom_range=0.1,
#                                    horizontal_flip=True)

batch_size = 16

class CustomDataGenerator(data_utils.Sequence):
    'Generates data for Keras'
    def __init__(self, list_IDs, batch_size=batch_size, dim=(400,400,3), shuffle=True):
        'Initialization'
        self.dim = dim
        self.batch_size = batch_size
        self.list_IDs = list_IDs
        self.shuffle = shuffle
        self.on_epoch_end()

    def __len__(self):
        'Denotes the number of batches per epoch'
        return int(np.floor(len(self.list_IDs) / self.batch_size))

    def __getitem__(self, index):
        'Generate one batch of data'
        # Generate indexes of the batch
        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]

        # Find list of IDs
        list_IDs_temp = [self.list_IDs[k] for k in indexes]

        # Generate data
        X,y= self.__data_generation(list_IDs_temp)
        #print(X.shape,y.shape)
        return X, y

    def on_epoch_end(self):
        'Updates indexes after each epoch'
        self.indexes = np.arange(len(self.list_IDs))
        if self.shuffle == True:
            np.random.shuffle(self.indexes)

    def __data_generation(self, list_IDs_temp):
        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)
        # Initialization
        X = np.empty((self.batch_size, *self.dim))
        for i,f in enumerate(list_IDs_temp):
            X[i,]=np.load(f)

        gray_batch=rgb2gray(X)

        X_batch=gray_batch[:,:,:]/255. #(16,400,400)
        X_batch=np.repeat(np.expand_dims(X_batch,3),3,axis=3)
        Y_batch=X[:,:,:,:]/255.
        return X_batch,Y_batch

print("LEN TRAINING:",len(train_image_globs))
train_dataGenerator=CustomDataGenerator(train_image_globs)

# def image_a_b_gen(batch_size):
#     for batch in train_dataGenerator.flow(dataset,
#                                           batch_size=batch_size,
#                                           target_size=(400, 400),
#                                           color_mode="rgb",
#                                           class_mode="input",
#                                           shuffle=True,
#                                           seed=42
#                                           ):
#         # print(">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>", len(batch), batch[0].shape, batch[1].shape)
#         gray_batch = rgb2gray(batch[0])
#
#         X_batch = gray_batch[:,:,:]/255. # Gray
#         Y_batch = batch[0][:,:,:,:]/255. # RGB
#         print(np.max(X_batch),np.min(X_batch),np.max(Y_batch),np.min(Y_batch))
#         yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch)

"""# Model creation"""
""" ORIGINAL CUSTOM MODEL
model = Sequential()
# model.add(InputLayer(input_shape=(256, 256, 1)))
model.add(InputLayer(input_shape=(400, 400, 1)))

model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))
model.add(AveragePooling2D(pool_size=(3,3),padding='same'))

model.add(Conv2D(32, (3, 3), activation='relu', padding='same', strides=2))
model.add(AveragePooling2D(pool_size=(3,3),padding='same'))

model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))

model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))

model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))

model.add(Conv2D(128, (3, 3), activation='relu', padding='same', strides=2))

model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))

model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))

model.add(Conv2DTranspose(128, (3, 3), activation='relu', padding='same'))
model.add(Conv2DTranspose(128, (3, 3), activation='relu', padding='same'))
model.add(UpSampling2D((3, 3)))
model.add(Conv2DTranspose(128, (3, 3), activation='relu', padding='same',strides=2))

model.add(UpSampling2D((3, 3)))
model.add(Conv2DTranspose(128, (3, 3), activation='relu', padding='same'))
# model.add(UpSampling2D((3, 3)))
model.add(Conv2DTranspose(64, (3, 3), activation='relu', padding='same'))
model.add(UpSampling2D((3, 3)))
model.add(Conv2DTranspose(64, (3, 3), activation='relu', padding='same'))
# model.add(UpSampling2D((3, 3)))
model.add(Conv2DTranspose(3, (3, 3), activation='tanh', padding='same'))
# model.add(UpSampling2D((3, 3)))
# model.add(Reshape((400,400,3)))

"""



model = Sequential()
# model.add(InputLayer(input_shape=(256, 256, 1)))
model.add(InputLayer(input_shape=(400, 400, 3)))
model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))
# model.add(AveragePooling2D(pool_size=(2,2),padding='valid'))
model.add(AveragePooling2D(pool_size=(3,3),padding='valid'))
model.add(Conv2D(32, (3, 3), activation='relu', padding='same', strides=2))
# model.add(AveragePooling2D(pool_size=(2,2),padding='valid'))
model.add(AveragePooling2D(pool_size=(3,3),padding='valid'))
model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
# model.add(AveragePooling2D(pool_size=(3,3),padding='valid'))
# model.add(AveragePooling2D(pool_size=(2,2),padding='valid'))
model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))
# model.add(AveragePooling2D(pool_size=(3,3),padding='valid'))
model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
# model.add(AveragePooling2D(pool_size=(3,3),padding='valid'))
model.add(Conv2D(128, (3, 3), activation='relu', padding='same', strides=2))
model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))
model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))
model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
model.add(UpSampling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
model.add(UpSampling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
model.add(UpSampling2D((2, 2))) # extra
# model.add(UpSampling2D((3, 3))) # extra
model.add(ZeroPadding2D((1, 1))) # extra
model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
# model.add(Conv2D(64, (3, 3), activation='relu', padding='valid'))
model.add(UpSampling2D((2, 2))) # extra
model.add(UpSampling2D((2, 2))) # extra
model.add(Conv2D(3, (3, 3), activation='tanh', padding='same'))
model.add(UpSampling2D((2, 2)))

"""# Model Training"""

# model.compile(optimizer='rmsprop', loss='mse', metrics = ['accuracy'])
model.compile(optimizer='adam',loss='mse',metrics=['accuracy'])


callback_earlystop=EarlyStopping(monitor='loss',patience=5)

checkpoint_filepath = 'Models/checkpoint/model2_{epoch:04d}.h5'
callback_checkpoint = ModelCheckpoint(
     filepath=checkpoint_filepath,
     save_weights_only=False,
     period=1)


model.summary()

model.fit_generator(train_dataGenerator,
                    epochs=20,
                    steps_per_epoch=len(train_image_globs)/batch_size,
                    callbacks=[callback_earlystop,callback_checkpoint],
                    use_multiprocessing=True,
                    workers=10,
                    max_queue_size=10)

now = datetime.now()
dt_string = now.strftime("%d_%m_%H_%M")
print(dt_string)
model.save('Models/Colorization_MODIS_Exp_Custom_' + dt_string)
