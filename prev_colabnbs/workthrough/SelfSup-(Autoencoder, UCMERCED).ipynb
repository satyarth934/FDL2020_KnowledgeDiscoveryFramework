{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SelfSup-(Autoencoder, UCMERCED).ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"561rrpfX_VaY","colab_type":"text"},"source":["**GET DATA**\n","\n","Summary of this notebook: ...\n","\n","Todo:\n","\n","1. Self supervised representation learning using colorization as a pretext task\n","2. Taking in an image I , rotating it by an a set angle A--> rotated image (I_A), rotated angle A (actual label) (Done)\n","3. Dataloader that does this somehow (Done)\n","4. Some model-> ResNet50  + new full-connected layer (feature vector-> probability that image belongs to one of n classes) (Done-ish)\n","5. Additional training with the above model minimizing the loss wrt. actual rotated angle\n","f(I_A)=min[L(A_predict,A)]\n","6. Save this new model\n","\n","7. Proof of concept:\n","Imagenet-> Train on Caltech validation on caltech\n","\n","\n","\n","\n","Definition of Done: ..."]},{"cell_type":"markdown","metadata":{"id":"CwvCiqy-ntV0","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"qL-k0CxJfnA6","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"6Ev8fWuVejb0","colab_type":"text"},"source":["# Imports\n"]},{"cell_type":"code","metadata":{"id":"z81q60U3G0ol","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595596151577,"user_tz":240,"elapsed":949,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}},"outputId":"2075f572-b300-4f2c-d23f-375a9798d647"},"source":["# Mount Google drive\n","from google.colab import drive\n","import os\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YgicpEBiG2d8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595596152261,"user_tz":240,"elapsed":1462,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}}},"source":["# Change to current dataset\n","os.chdir(\"/content/gdrive/Shared drives/2020_FDLUSA_Earth Science_Knowledge Discovery Framework/Code\")"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"TKfFt17nGyDm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595596153595,"user_tz":240,"elapsed":2632,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}},"outputId":"3c8c5f1c-faa5-4fce-ac77-f7e517178c51"},"source":["# Imports from Colab 2\n","import math\n","import numpy as np\n","import pickle\n","import keras\n","import tensorflow\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Import model architecture\n","from tensorflow.keras.applications import VGG16"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"gFkitrY7HMwz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595596153801,"user_tz":240,"elapsed":2682,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}}},"source":["# Imports for Colab 6\n","import cv2 # Read raw image\n","import glob\n","from google.colab.patches import cv2_imshow\n","from matplotlib import pyplot as plt\n","from scipy import ndimage # For rotation task or\n","import imutils\n","from tensorflow.keras import Model\n","from tensorflow.keras.layers import Dense, Flatten, Dropout\n","from tensorflow.keras.optimizers import Adam\n","\n","from tensorflow.python.keras.utils import data_utils\n","from tensorflow.keras.preprocessing.image import Iterator\n","\n","\n","# Imports for Colorizer\n","from os import path\n","from tensorflow.keras import Input\n","from tensorflow.keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, AveragePooling2D, MaxPooling2D, Reshape, Conv2DTranspose, ZeroPadding2D, Add\n","from tensorflow.keras.layers import Activation, InputLayer, BatchNormalization\n","from tensorflow.keras.callbacks import TensorBoard\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","from skimage.color import rgb2lab, lab2rgb, rgb2gray\n","from skimage.io import imsave\n","import random\n","import tensorflow as tf\n","from skimage.transform import resize\n","from tensorflow.keras.layers import PReLU\n","\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"7AX-W5mqG4xD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1595596155007,"user_tz":240,"elapsed":3731,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}},"outputId":"4e612393-e66a-4816-a043-f2d976a4d3ac"},"source":["# Check to see if GPU is being used\n","tensorflow.test.gpu_device_name()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"KzmeP_R9ep5w","colab_type":"text"},"source":["# Data Augmentation/Analysis"]},{"cell_type":"code","metadata":{"id":"n2rPBilY_w-X","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595596155008,"user_tz":240,"elapsed":3467,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}}},"source":["# Raw dataset/path/model paths\n","dataset = \"UCMerced_LandUse\"\n","dataPath = (\"Datasets/\"+ dataset+ \"/Splits_2\")\n","\n","train_image_globs=glob.glob(dataPath+'/train/**/*.tif')\n","val_image_globs=glob.glob(dataPath+'/val/**/*.tif')"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FNBiKT_Qe0xr","colab_type":"text"},"source":["# Dataloader creation and test"]},{"cell_type":"code","metadata":{"id":"cnwO8mvVvWFT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1595596232067,"user_tz":240,"elapsed":80243,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}},"outputId":"faa0b9fa-1aef-4923-ce1e-f4856a60d600"},"source":["dims=(448,448,3)\n","\n","train_name='merced_xtrain.npy'\n","test_name='merced_xtest.npy'\n","\n","if path.exists(train_name):\n","  print(\"Train exists\")\n","  X_train=np.load(train_name)\n","else:\n","  X_train=np.empty((0,*dims))\n","\n","  # for f in train_image_globs:\n","  #   image=np.expand_dims(img_to_array(load_img(f,target_size=dims))/255.,0)\n","  #   X_train=np.vstack((X_train,image))\n","\n","  # with open(train_name, 'wb') as f:\n","  #   np.save(f,X_train,allow_pickle=True)\n","  \n","\n","if path.exists(test_name):\n","  print(\"Test exists\")\n","  X_test=np.load(test_name)\n","else:\n","  X_test=np.empty((0,*dims))\n","\n","#   for f in val_image_globs:\n","#     image=np.expand_dims(img_to_array(load_img(f,target_size=dims))/255.,0)\n","#     X_test=np.vstack((X_test,image))\n","\n","#   with open(test_name, 'wb') as f:\n","#     np.save(f,X_test,allow_pickle=True)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Train exists\n","Test exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PsMasbyYGysD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595596232068,"user_tz":240,"elapsed":80105,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}},"outputId":"ad816544-b21e-4ddf-b6c0-a897d0925b24"},"source":["\n","print(X_train.shape,X_test.shape)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["(1680, 256, 256, 3) (420, 256, 256, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Kt6oH37M-_VN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595596232068,"user_tz":240,"elapsed":79976,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}}},"source":["train_dataGenerator = ImageDataGenerator(rotation_range=20,\n","                                   width_shift_range=0.1,\n","                                   height_shift_range=0.1,\n","                                   zoom_range=0.1,\n","                                   horizontal_flip=True)\n","valid_dataGenerator = ImageDataGenerator()\n","batch_size = 16\n","\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EklPj1Gg5ZC-","colab":{},"executionInfo":{"status":"ok","timestamp":1595596232069,"user_tz":240,"elapsed":79854,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}}},"source":["\n","# def batch_lab(batch_size,channel_pred):\n","#   for batch in train_dataGenerator.flow(X_train,batch_size=batch_size):\n","#     lab_batch=rgb2lab(batch)\n","\n","#     if channel_pred==\"0\":\n","#       X_batch=lab_batch[:,:,:,[0]]\n","#       Y_batch=lab_batch[:,:,:,[1,2]]\n","#     elif channel_pred==\"1_2\":\n","#       X_batch=lab_batch[:,:,:,[1,2]]\n","#       Y_batch=lab_batch[:,:,:,[0]]\n","#     yield X_batch,Y_batch\n","\n","def batch_lab(batch_size,data_generator,data): # Does basically nothing, but just to help with later tasks\n","  for batch in data_generator.flow(data,batch_size=batch_size):\n","    # print(batch.shape)\n","    batch=resize(batch,(batch_size,*dims))\n","    # print(batch.shape)\n","    yield batch,batch"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ri-SDcocunWM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595596232069,"user_tz":240,"elapsed":79297,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}}},"source":["def custom_loss(y_true, y_pred):\n","  y_true_hist=tf.histogram_fixed_width(y_true, value_range=(-1., 1.), nbins=20) \n","  y_pred_hist=tf.histogram_fixed_width( y_pred, value_range=(-1., 1.), nbins=20) \n","  return K.mean(K.square(y_true_hist-y_pred_hist)) + y_pred*0 "],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1QAgBBBNfDAx","colab_type":"text"},"source":["# Model creation"]},{"cell_type":"code","metadata":{"id":"Y1io4UxIu0Vr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595596232576,"user_tz":240,"elapsed":78172,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}}},"source":["def network(input_shape):\n","\n","    model = Sequential(name=\"enc_dec\")\n","    model.add(Input(shape=input_shape))\n","    model.add(Conv2D(32, (3, 3), padding=\"same\", strides=2))\n","    model.add(PReLU())\n","    model.add(Conv2D(64, (3, 3), padding=\"same\"))\n","    model.add(PReLU())\n","    model.add(Conv2D(64, (3, 3), padding=\"same\", strides=2))\n","    model.add(PReLU())\n","    model.add(Conv2D(128, (3, 3), padding=\"same\"))\n","    model.add(PReLU())\n","    model.add(Conv2D(128, (3, 3), padding=\"same\", strides=2))\n","    model.add(PReLU())\n","    model.add(Conv2D(256, (3, 3), padding=\"same\"))\n","    model.add(PReLU())\n","    model.add(Conv2D(256, (3, 3), padding=\"same\", strides=2))\n","    model.add(PReLU())\n","    model.add(Conv2D(15, (3, 3), padding=\"same\"))\n","    model.add(PReLU())\n","    model.add(Conv2D(5, (3, 3), padding=\"same\"))\n","    model.add(PReLU())\n","    model.add(Conv2DTranspose(128, (3, 3), padding=\"same\"))\n","    model.add(PReLU())\n","    model.add(UpSampling2D((2, 2)))\n","    model.add(Conv2DTranspose(64, (3, 3),padding=\"same\"))\n","    model.add(PReLU())\n","    model.add(Conv2DTranspose(64, (3, 3), padding=\"same\"))\n","    model.add(PReLU())\n","    model.add(UpSampling2D((2, 2)))\n","    model.add(Conv2DTranspose(32, (3, 3), padding=\"same\"))\n","    model.add(PReLU())\n","    model.add(Conv2D(3, (3, 3), padding=\"same\"))\n","    model.add(PReLU())\n","    model.add(UpSampling2D((2, 2)))\n","    model.add(Conv2DTranspose(3, (3, 3), padding=\"same\"))\n","    model.add(PReLU())\n","    model.add(UpSampling2D((2, 2)))\n","    model.add(Conv2DTranspose(3, (3, 3), activation=\"tanh\", padding=\"same\"))\n","    return model\n","\n","\n","\n","\n","# def decoder(input_shape):\n","#     model = Sequential(name=\"decoder\")\n","#     model.add(Input(shape=input_shape))\n","#     model.add(Conv2DTranspose(128, (3, 3), padding=\"same\"))\n","#     model.add(PReLU())\n","#     model.add(UpSampling2D((2, 2)))\n","#     model.add(Conv2DTranspose(64, (3, 3),padding=\"same\"))\n","#     model.add(PReLU())\n","#     model.add(Conv2DTranspose(64, (3, 3), padding=\"same\"))\n","#     model.add(PReLU())\n","#     model.add(UpSampling2D((2, 2)))\n","#     model.add(Conv2DTranspose(32, (3, 3), padding=\"same\"))\n","#     model.add(PReLU())\n","#     model.add(Conv2D(3, (3, 3), padding=\"same\"))\n","#     model.add(PReLU())\n","#     model.add(UpSampling2D((2, 2)))\n","#     model.add(Conv2DTranspose(3, (3, 3), padding=\"same\"))\n","#     model.add(PReLU())\n","#     model.add(UpSampling2D((2, 2)))\n","#     model.add(Conv2DTranspose(3, (3, 3), activation=\"tanh\", padding=\"same\"))\n","#     return model\n","\n","\n","# encoder_model=encoder(dims)\n","# encoding_depth=15\n","\n","# print(encoder_model.summary())\n","# decoder_model=decoder(encoder_model.output_shape[1:])\n","# print(decoder_model.summary())\n","\n","complete_model = network(input_shape=dims)\n","\n","# complete_model.build(input_shape=(None,*dims))\n","# print(complete_model.summary())\n","\n"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tsgBqD4dfHoE","colab_type":"text"},"source":["# Model Training"]},{"cell_type":"code","metadata":{"id":"LoPPvZ9Gkm7_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595596232576,"user_tz":240,"elapsed":72214,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}},"outputId":"399f6d43-9c52-4748-e047-e588410a24bd"},"source":["complete_model.compile(optimizer='rmsprop', loss='mse')\n","complete_model.summary()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Model: \"enc_dec\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 224, 224, 32)      896       \n","_________________________________________________________________\n","p_re_lu (PReLU)              (None, 224, 224, 32)      1605632   \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 224, 224, 64)      18496     \n","_________________________________________________________________\n","p_re_lu_1 (PReLU)            (None, 224, 224, 64)      3211264   \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 112, 112, 64)      36928     \n","_________________________________________________________________\n","p_re_lu_2 (PReLU)            (None, 112, 112, 64)      802816    \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","p_re_lu_3 (PReLU)            (None, 112, 112, 128)     1605632   \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 56, 56, 128)       147584    \n","_________________________________________________________________\n","p_re_lu_4 (PReLU)            (None, 56, 56, 128)       401408    \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","p_re_lu_5 (PReLU)            (None, 56, 56, 256)       802816    \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 28, 28, 256)       590080    \n","_________________________________________________________________\n","p_re_lu_6 (PReLU)            (None, 28, 28, 256)       200704    \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 28, 28, 15)        34575     \n","_________________________________________________________________\n","p_re_lu_7 (PReLU)            (None, 28, 28, 15)        11760     \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 28, 28, 5)         680       \n","_________________________________________________________________\n","p_re_lu_8 (PReLU)            (None, 28, 28, 5)         3920      \n","_________________________________________________________________\n","conv2d_transpose (Conv2DTran (None, 28, 28, 128)       5888      \n","_________________________________________________________________\n","p_re_lu_9 (PReLU)            (None, 28, 28, 128)       100352    \n","_________________________________________________________________\n","up_sampling2d (UpSampling2D) (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","conv2d_transpose_1 (Conv2DTr (None, 56, 56, 64)        73792     \n","_________________________________________________________________\n","p_re_lu_10 (PReLU)           (None, 56, 56, 64)        200704    \n","_________________________________________________________________\n","conv2d_transpose_2 (Conv2DTr (None, 56, 56, 64)        36928     \n","_________________________________________________________________\n","p_re_lu_11 (PReLU)           (None, 56, 56, 64)        200704    \n","_________________________________________________________________\n","up_sampling2d_1 (UpSampling2 (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","conv2d_transpose_3 (Conv2DTr (None, 112, 112, 32)      18464     \n","_________________________________________________________________\n","p_re_lu_12 (PReLU)           (None, 112, 112, 32)      401408    \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 112, 112, 3)       867       \n","_________________________________________________________________\n","p_re_lu_13 (PReLU)           (None, 112, 112, 3)       37632     \n","_________________________________________________________________\n","up_sampling2d_2 (UpSampling2 (None, 224, 224, 3)       0         \n","_________________________________________________________________\n","conv2d_transpose_4 (Conv2DTr (None, 224, 224, 3)       84        \n","_________________________________________________________________\n","p_re_lu_14 (PReLU)           (None, 224, 224, 3)       150528    \n","_________________________________________________________________\n","up_sampling2d_3 (UpSampling2 (None, 448, 448, 3)       0         \n","_________________________________________________________________\n","conv2d_transpose_5 (Conv2DTr (None, 448, 448, 3)       84        \n","=================================================================\n","Total params: 11,071,650\n","Trainable params: 11,071,650\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h8DTqil93q_X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1595596325219,"user_tz":240,"elapsed":4350,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}},"outputId":"79217cd8-c556-4174-aba0-edd61cdcac4b"},"source":["!pip install tf-explain\n","from tf_explain.callbacks.activations_visualization import ActivationsVisualizationCallback\n","# Define the Activation Visualization callback\n","output_dir = './visualizations'\n","callbacks = [\n","    ActivationsVisualizationCallback(\n","        validation_data=(X_test, X_test),\n","        layers_name=['conv2d_8'],\n","        output_dir=output_dir,\n","    ),\n","]"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tf-explain in /usr/local/lib/python3.6/dist-packages (0.2.1)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.6/dist-packages (from tf-explain) (4.1.2.30)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python>=4.1.0.25->tf-explain) (1.18.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YdOe_DrN625Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1595596668142,"user_tz":240,"elapsed":345454,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}},"outputId":"fbc0a270-2a03-4915-cac0-db7253620a81"},"source":["complete_model.fit_generator(batch_lab(batch_size,train_dataGenerator,X_train),\n","                    epochs=50,\n","                    steps_per_epoch=len(X_train)/batch_size,\n","                    validation_data=batch_lab(batch_size,valid_dataGenerator,X_test),\n","                    validation_steps=len(X_test)/batch_size,\n","                    callbacks=callbacks)\n"],"execution_count":15,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-15-102bb618f169>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use Model.fit, which supports generators.\n","Epoch 1/50\n","105/105 [==============================] - ETA: 0s - loss: 0.0686WARNING:tensorflow:Model was constructed with shape (None, 448, 448, 3) for input Tensor(\"input_1:0\", shape=(None, 448, 448, 3), dtype=float32), but it was called on an input with incompatible shape (None, 256, 256, 3).\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-102bb618f169>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_lab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_dataGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     callbacks=callbacks)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1477\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m   @deprecation.deprecated(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    874\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tf_explain/callbacks/activations_visualization.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \"\"\"\n\u001b[1;32m     49\u001b[0m         \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtractActivations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# Using the file writer, log the reshaped image.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tf_explain/core/activations.py\u001b[0m in \u001b[0;36mexplain\u001b[0;34m(self, validation_data, model, layers_name)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         predictions = activations_model.predict(\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         )\n\u001b[1;32m     36\u001b[0m         \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1266\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1122 predict_step  **\n        return self(x, training=False)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:719 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:888 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/advanced_activations.py:161 call\n        neg = -self.alpha * K.relu(-inputs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:984 binary_op_wrapper\n        return func(x, y, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:1283 _mul_dispatch\n        return gen_math_ops.mul(x, y, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py:6092 mul\n        \"Mul\", x=x, y=y, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:595 _create_op_internal\n        compute_device)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:3327 _create_op_internal\n        op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1817 __init__\n        control_input_ops, op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1657 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 224 and 128 for '{{node model/p_re_lu/mul}} = Mul[T=DT_FLOAT](model/p_re_lu/Neg, model/p_re_lu/Relu_1)' with input shapes: [224,224,32], [?,128,128,32].\n"]}]},{"cell_type":"code","metadata":{"id":"kKAAVsxOilTL","colab_type":"code","colab":{}},"source":["model.save('Models/Colorization_CustomCNN_epoch30_ucmerced')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AoNBrpVzOxWJ","colab_type":"text"},"source":["## Model Testing"]},{"cell_type":"code","metadata":{"id":"95ws7iOdej6L","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595594931726,"user_tz":240,"elapsed":35562,"user":{"displayName":"Satyarth Praveen","photoUrl":"","userId":"10200372647351599705"}}},"source":["model=load_model('Models/Colorization_CustomCNN_epoch30_ucmerced')"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"0xLbk6TMXyW8","colab_type":"code","colab":{}},"source":["for i in range(10):\n","  index=np.random.randint(0,len(X_test))\n","\n","  X_test_im=rgb2gray(np.expand_dims(X_test[index],0))\n","  X_test_im=np.repeat(np.expand_dims(X_test_im,3),3,axis=3)\n","\n","  out_image=np.squeeze(model.predict(X_test_im))\n","\n","  fig=plt.figure()\n","  plt.subplot(1, 3, 1)\n","  plt.imshow(X_test[index])\n","  plt.subplot(1,3,2)\n","  plt.imshow(np.squeeze(X_test_im))\n","  plt.subplot(1,3,3)\n","  plt.imshow(out_image)\n","  plt.show()\n","\n","  \n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IDKp3r-IYOla","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ns2CZFPpO0tR","colab_type":"code","colab":{}},"source":["X_test_m = rgb2lab(X_test)[:,:,:,0]\n","X_test_m = X_test_m.reshape(X_test_m.shape+(1,))\n","Y_test = rgb2lab(X_test)[:,:,:,1:]\n","Y_test = Y_test / 128\n","print(model.evaluate(X_test_m, Y_test, batch_size=batch_size))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jSJP17H2P5yr","colab_type":"code","colab":{}},"source":["rand_index=np.random.randint(0,len(val_image_globs))\n","\n","sample_image=img_to_array(load_img(val_image_globs[rand_index]))\n","sample_image=np.expand_dims(sample_image/255.,0)\n","\n","sample_image_x=rgb2lab(sample_image)[:,:,:,0]\n","sample_image_x=sample_image_x.reshape(sample_image_x.shape+(1,))\n","\n","# Test model\n","output = model.predict(sample_image_x)\n","output = output * 128\n","\n","# Output colorizations\n","for i in range(len(output)):\n","    cur = np.zeros((256, 256, 3))\n","    cur[:,:,0] = sample_image_x[i][:,:,0]\n","    cur[:,:,1:] = output[i]\n","    imsave(\"Models/colorization_out/img_\"+str(rand_index)+\".png\", lab2rgb(cur))\n","    imsave(\"Models/colorization_out/raw_img_\"+str(rand_index)+\".png\",np.squeeze(sample_image))\n","\n"],"execution_count":null,"outputs":[]}]}